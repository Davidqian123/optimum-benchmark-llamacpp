defaults:
  - llama_peft
  - _self_

experiment_name: llama_peft+bnb

backend:
  quantization_strategy: bnb
  quantization_config:
    load_in_4bit: true
    bnb_4bit_compute_dtype: float16