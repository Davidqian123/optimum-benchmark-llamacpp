experiment_name,backend.name,backend.version,backend._target_,backend.seed,backend.inter_op_num_threads,backend.intra_op_num_threads,backend.initial_isolation_check,backend.continous_isolation_check,backend.delete_cache,backend.no_weights,backend.device_map,backend.torch_dtype,backend.disable_grad,backend.eval_mode,backend.amp_autocast,backend.amp_dtype,backend.torch_compile,backend.bettertransformer,backend.quantization_strategy,backend.quantization_config.load_in_8bit,backend.quantization_config.load_in_4bit,backend.quantization_config.llm_int8_threshold,backend.quantization_config.bnb_4bit_compute_dtype,backend.use_ddp,backend.peft_strategy,backend.peft_config.base_model_name_or_path,backend.peft_config.revision,backend.peft_config.peft_type,backend.peft_config.task_type,backend.peft_config.inference_mode,backend.peft_config.auto_mapping,backend.peft_config.r,backend.peft_config.target_modules,backend.peft_config.lora_alpha,backend.peft_config.lora_dropout,backend.peft_config.fan_in_fan_out,backend.peft_config.bias,backend.peft_config.modules_to_save,backend.peft_config.init_lora_weights,backend.peft_config.layers_to_transform,backend.peft_config.layers_pattern,benchmark.name,benchmark._target_,benchmark.warmup_steps,benchmark.dataset_shapes.dataset_size,benchmark.dataset_shapes.sequence_length,benchmark.dataset_shapes.num_choices,benchmark.dataset_shapes.feature_size,benchmark.dataset_shapes.nb_max_frames,benchmark.dataset_shapes.audio_sequence_length,benchmark.training_arguments.skip_memory_metrics,benchmark.training_arguments.output_dir,benchmark.training_arguments.use_cpu,benchmark.training_arguments.ddp_find_unused_parameters,benchmark.training_arguments.do_train,benchmark.training_arguments.do_eval,benchmark.training_arguments.do_predict,benchmark.training_arguments.report_to,benchmark.training_arguments.max_steps,benchmark.training_arguments.per_device_train_batch_size,model,device,task,hub_kwargs.revision,hub_kwargs.cache_dir,hub_kwargs.force_download,hub_kwargs.local_files_only,environment.optimum_version,environment.transformers_version,environment.accelerate_version,environment.diffusers_version,environment.python_version,environment.system,environment.cpu,environment.cpu_count,environment.cpu_ram_mb,environment.gpu,Unnamed: 0,warmup.runtime(s),warmup.throughput(samples/s),training.runtime(s),training.throughput(samples/s),overall_training.runtime(s),overall_training.throughput(samles/s),backend.quantization_config.bits,backend.quantization_config.disable_exllama
llama_peft+bnb,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,bnb,False,True,0.0,float16,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,4,meta-llama/Llama-2-7b-hf,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD Ryzen 9 7950X 16-Core Processor,32,134796,NVIDIA GeForce RTX 4090,0,11.296959400177002,14.16310303792834,16.940354824066162,14.167353782876267,28.2373149394989,8.499391691958762,,
llama_peft+bnb,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,bnb,False,True,0.0,float16,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,2,meta-llama/Llama-2-7b-hf,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD Ryzen 9 7950X 16-Core Processor,32,134796,NVIDIA GeForce RTX 4090,0,6.557464122772217,12.19983800173342,9.813016176223757,12.228656087488323,16.37048101425171,7.330267198351176,,
llama_peft+bnb,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,bnb,False,True,0.0,float16,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,1,meta-llama/Llama-2-7b-hf,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD Ryzen 9 7950X 16-Core Processor,32,134796,NVIDIA GeForce RTX 4090,0,4.717145681381226,8.479704190159252,6.284568548202515,9.547194773961204,11.001714944839478,5.4536952012325965,,
llama_peft+gptq,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,gptq,,,,,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,2,TheBloke/Llama-2-7B-GPTQ,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD Ryzen 9 7950X 16-Core Processor,32,134796,NVIDIA GeForce RTX 4090,0,9.620262622833252,8.315781297916303,14.422025680541992,8.320606456962729,24.04228925704956,4.991205234951335,4,True
llama_peft+gptq,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,gptq,,,,,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,1,TheBloke/Llama-2-7B-GPTQ,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD Ryzen 9 7950X 16-Core Processor,32,134796,NVIDIA GeForce RTX 4090,0,7.74604344367981,5.16392662794023,11.014644145965576,5.44729354892293,18.760688304901123,3.198176901874402,4,True
