experiment_name,backend.name,backend.version,backend._target_,backend.seed,backend.inter_op_num_threads,backend.intra_op_num_threads,backend.initial_isolation_check,backend.continous_isolation_check,backend.delete_cache,backend.no_weights,backend.device_map,backend.torch_dtype,backend.disable_grad,backend.eval_mode,backend.amp_autocast,backend.amp_dtype,backend.torch_compile,backend.bettertransformer,backend.quantization_strategy,backend.quantization_config.load_in_8bit,backend.quantization_config.load_in_4bit,backend.quantization_config.llm_int8_threshold,backend.quantization_config.bnb_4bit_compute_dtype,backend.use_ddp,backend.peft_strategy,backend.peft_config.base_model_name_or_path,backend.peft_config.revision,backend.peft_config.peft_type,backend.peft_config.task_type,backend.peft_config.inference_mode,backend.peft_config.auto_mapping,backend.peft_config.r,backend.peft_config.target_modules,backend.peft_config.lora_alpha,backend.peft_config.lora_dropout,backend.peft_config.fan_in_fan_out,backend.peft_config.bias,backend.peft_config.modules_to_save,backend.peft_config.init_lora_weights,backend.peft_config.layers_to_transform,backend.peft_config.layers_pattern,benchmark.name,benchmark._target_,benchmark.warmup_steps,benchmark.dataset_shapes.dataset_size,benchmark.dataset_shapes.sequence_length,benchmark.dataset_shapes.num_choices,benchmark.dataset_shapes.feature_size,benchmark.dataset_shapes.nb_max_frames,benchmark.dataset_shapes.audio_sequence_length,benchmark.training_arguments.skip_memory_metrics,benchmark.training_arguments.output_dir,benchmark.training_arguments.use_cpu,benchmark.training_arguments.ddp_find_unused_parameters,benchmark.training_arguments.do_train,benchmark.training_arguments.do_eval,benchmark.training_arguments.do_predict,benchmark.training_arguments.report_to,benchmark.training_arguments.max_steps,benchmark.training_arguments.per_device_train_batch_size,model,device,task,hub_kwargs.revision,hub_kwargs.cache_dir,hub_kwargs.force_download,hub_kwargs.local_files_only,environment.optimum_version,environment.transformers_version,environment.accelerate_version,environment.diffusers_version,environment.python_version,environment.system,environment.cpu,environment.cpu_count,environment.cpu_ram_mb,environment.gpu,Unnamed: 0,warmup.runtime(s),warmup.throughput(samples/s),training.runtime(s),training.throughput(samples/s),overall_training.runtime(s),overall_training.throughput(samles/s),backend.quantization_config.bits,backend.quantization_config.disable_exllama,benchmark.training_arguments.num_train_epochs
llama_peft+bnb,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,bnb,False,True,0.0,float16,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,16,meta-llama/Llama-2-7b-hf,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,540684,NVIDIA A100-SXM4-80GB,0,37.89076852798462,16.89065766843239,56.87740755081177,16.878406406662933,94.76817727088928,10.129982739415745,,,
llama_peft+bnb,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,bnb,False,True,0.0,float16,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,8,meta-llama/Llama-2-7b-hf,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,540684,NVIDIA A100-SXM4-80GB,0,20.918142557144165,15.29772536571181,31.05281090736389,15.457537851627222,51.97095489501953,9.235928048072084,,,
llama_peft+gptq,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,gptq,,,,,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,16,TheBloke/Llama-2-7B-GPTQ,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,540684,NVIDIA A100-SXM4-80GB,0,42.25103163719177,15.147559129340534,62.30103039741516,15.409054936591064,104.5520634651184,9.18202824681967,4,True,1
llama_peft+bnb,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,bnb,False,True,0.0,float16,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,4,meta-llama/Llama-2-7b-hf,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,540684,NVIDIA A100-SXM4-80GB,0,12.387670040130615,12.91606892027881,18.496866941452023,12.975170376673516,30.884538888931274,7.770878524788781,,,
llama_peft+gptq,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,gptq,,,,,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,8,TheBloke/Llama-2-7B-GPTQ,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,540684,NVIDIA A100-SXM4-80GB,0,25.21270442008972,12.69201410004319,37.166062116622925,12.915008280775456,62.3787682056427,7.694925914817597,4,True,1
llama_peft+bnb,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,bnb,False,True,0.0,float16,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,2,meta-llama/Llama-2-7b-hf,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,540684,NVIDIA A100-SXM4-80GB,0,7.826598644256592,10.22155391329624,11.66720199584961,10.285242343681697,19.49380230903625,6.155802654486477,,,
llama_peft+gptq,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,gptq,,,,,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,4,TheBloke/Llama-2-7B-GPTQ,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,540684,NVIDIA A100-SXM4-80GB,0,16.28449511528015,9.825296938427522,24.11663317680359,9.951637869204824,40.40113019943237,5.940427874549211,4,True,1
llama_peft+gptq,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,gptq,,,,,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,2,TheBloke/Llama-2-7B-GPTQ,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,540684,NVIDIA A100-SXM4-80GB,0,11.56166124343872,6.919420861374939,17.316346883773804,6.929868107022354,28.878009557724,4.155411049370735,4,True,1
llama_peft+bnb,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,bnb,False,True,0.0,float16,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,1,meta-llama/Llama-2-7b-hf,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,540684,NVIDIA A100-SXM4-80GB,0,6.863541841506958,5.8278948280174845,8.946377992630005,6.706624742373706,15.809921264648438,3.795085313559543,,,
llama_peft+gptq,pytorch,2.0.1,optimum_benchmark.backends.pytorch.backend.PyTorchBackend,42,,,True,True,False,False,,float16,False,False,False,,False,False,gptq,,,,,False,lora,,,,CAUSAL_LM,False,,8,,8,0,False,none,,True,,,training,optimum_benchmark.benchmarks.training.benchmark.TrainingBenchmark,40,620,256,1,80,3000,16000,True,./trainer_output,False,False,True,False,False,none,100,1,TheBloke/Llama-2-7B-GPTQ,cuda:0,text-generation,main,,False,False,1.12.1.dev0,4.33.0.dev0,0.23.0.dev0,0.21.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,540684,NVIDIA A100-SXM4-80GB,0,10.04498553276062,3.982086372304309,13.854225873947144,4.330808559490136,23.899213075637817,2.5105429124426824,4,True,1
