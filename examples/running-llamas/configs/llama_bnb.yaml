defaults:
  - llama_baseline
  - _self_

experiment_name: llama_bnb

backend:
  quantization_strategy: bnb
  quantization_config:
    load_in_4bit: true
    bnb_4bit_compute_dtype: float16