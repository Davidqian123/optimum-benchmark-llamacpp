defaults:
  - backend: pytorch # default backend
  - benchmark: inference # default benchmark
  - experiment # inheriting from experiment config
  - _self_ # for hydra 1.1 compatibility
  - override hydra/job_logging: colorlog # colorful logging
  - override hydra/hydra_logging: colorlog # colorful logging

hydra:
  run:
    dir: experiments/${experiment_name}_batch_size(${benchmark.input_shapes.batch_size})_new_tokens(${benchmark.new_tokens})
  sweep:
    dir: experiments/${experiment_name}_batch_size(${benchmark.input_shapes.batch_size})_new_tokens(${benchmark.new_tokens})
  job:
    chdir: true # to change the working directory during the run/sweep directory
    env_set:
      CUDA_VISIBLE_DEVICES: 3
  sweeper:
    max_batch_size: 1
    params:
      benchmark.input_shapes.batch_size: 1,16
      benchmark.new_tokens: 100,1000

experiment_name: llama_baseline
model: meta-llama/Llama-2-7b-hf
device: cuda:0

backend:
  torch_dtype: float16

benchmark:
  memory: true
  warmup_runs: 10
  input_shapes:
    batch_size: null
  new_tokens: null