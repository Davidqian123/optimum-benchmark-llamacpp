defaults:
  - llama_baseline
  - _self_

experiment_name: llama_gptq
model: TheBloke/Llama-2-7B-GPTQ

backend:
  quantization_strategy: gptq
  quantization_config:
    bits: 4
