experiment_name,backend.name,backend.version,backend._target_,backend.inter_op_num_threads,backend.intra_op_num_threads,backend.initial_isolation_check,backend.continous_isolation_check,backend.delete_cache,backend.export,backend.no_weights,backend.use_merged,backend.use_cache,backend.torch_dtype,backend.provider,backend.device_id,backend.use_io_binding,backend.enable_profiling,backend.optimization,backend.optimization_config.optimization_level,backend.optimization_config.optimize_for_gpu,backend.optimization_config.fp16,backend.optimization_config.enable_transformers_specific_optimizations,backend.optimization_config.enable_gelu_approximation,backend.optimization_config.disable_gelu_fusion,backend.optimization_config.disable_layer_norm_fusion,backend.optimization_config.disable_attention_fusion,backend.optimization_config.disable_skip_layer_norm_fusion,backend.optimization_config.disable_bias_skip_layer_norm_fusion,backend.optimization_config.disable_bias_gelu_fusion,backend.optimization_config.use_mask_index,backend.optimization_config.no_attention_mask,backend.optimization_config.disable_embed_layer_norm_fusion,backend.optimization_config.disable_shape_inference,backend.optimization_config.use_multi_head_attention,backend.optimization_config.enable_gemm_fast_gelu_fusion,backend.optimization_config.use_raw_attention_mask,backend.optimization_config.disable_group_norm_fusion,backend.optimization_config.disable_packed_kv,backend.auto_optimization,backend.auto_optimization_config.for_gpu,backend.quantization,backend.quantization_config.is_static,backend.quantization_config.format,backend.quantization_config.mode,backend.quantization_config.activations_dtype,backend.quantization_config.activations_symmetric,backend.quantization_config.weights_dtype,backend.quantization_config.weights_symmetric,backend.quantization_config.per_channel,backend.quantization_config.reduce_range,backend.quantization_config.operators_to_quantize,backend.auto_quantization,backend.auto_quantization_config.is_static,backend.calibration,backend.calibration_config.dataset_name,backend.calibration_config.num_samples,backend.calibration_config.dataset_config_name,backend.calibration_config.dataset_split,backend.calibration_config.preprocess_batch,backend.calibration_config.preprocess_class,backend.use_ortmodel,benchmark.name,benchmark._target_,benchmark.seed,benchmark.memory,benchmark.warmup_runs,benchmark.benchmark_duration,benchmark.input_shapes.batch_size,benchmark.input_shapes.sequence_length,benchmark.input_shapes.num_choices,benchmark.input_shapes.width,benchmark.input_shapes.height,benchmark.input_shapes.num_channels,benchmark.input_shapes.point_batch_size,benchmark.input_shapes.nb_points_per_image,benchmark.input_shapes.feature_size,benchmark.input_shapes.nb_max_frames,benchmark.input_shapes.audio_sequence_length,benchmark.new_tokens,model,device,task,hub_kwargs.revision,hub_kwargs.cache_dir,hub_kwargs.force_download,hub_kwargs.local_files_only,hub_kwargs.use_auth_token,environment.optimum_version,environment.transformers_version,environment.accelerate_version,environment.diffusers_version,environment.python_version,environment.system,environment.cpu,environment.cpu_count,environment.cpu_ram_mb,Unnamed: 0,forward.latency(s),forward.throughput(samples/s),generate.latency(s),generate.throughput(tokens/s),backend.load_in_8bit,backend.load_in_4bit,backend.bettertransformer,backend.torch_compile,backend.torch_compile_config.fullgraph,backend.torch_compile_config.dynamic,backend.torch_compile_config.backend,backend.torch_compile_config.mode,backend.torch_compile_config.options,backend.torch_compile_config.disable,backend.amp_autocast,backend.amp_dtype,backend.disable_grad,backend.eval_mode,forward.speedup(%),generate.speedup(%)
whisper_auto_opt(O4),onnxruntime,1.15.1,optimum_benchmark.backends.onnxruntime.ORTBackend,,,False,False,False,True,False,False,True,,CUDAExecutionProvider,1,True,False,False,1,True,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O4,True,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",,False,False,glue,300,sst2,train,True,optimum_benchmark.preprocessors.glue.GluePreprocessor,True,inference,optimum_benchmark.benchmarks.inference.InferenceBenchmark,42,False,10,10,64,16,1,64,64,3,3,2,80,3000,16000,100,openai/whisper-base,cuda:1,automatic-speech-recognition,main,,False,False,False,1.11.1.dev0,4.32.0.dev0,0.22.0.dev0,0.20.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,515637,0,0.0666,961.0,0.65,9850.0,,,,,,,,,,,,,,,36.699857752489336,48.567119155354455
whisper_auto_opt(O3),onnxruntime,1.15.1,optimum_benchmark.backends.onnxruntime.ORTBackend,,,False,False,False,True,False,False,True,,CUDAExecutionProvider,1,True,False,False,1,True,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O3,True,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",,False,False,glue,300,sst2,train,True,optimum_benchmark.preprocessors.glue.GluePreprocessor,True,inference,optimum_benchmark.benchmarks.inference.InferenceBenchmark,42,False,10,10,64,16,1,64,64,3,3,2,80,3000,16000,100,openai/whisper-base,cuda:1,automatic-speech-recognition,main,,False,False,False,1.11.1.dev0,4.32.0.dev0,0.22.0.dev0,0.20.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,515637,0,0.169,379.0,0.621,10300.0,,,,,,,,,,,,,,,-46.08819345661451,55.35444947209653
whisper_auto_opt(O2),onnxruntime,1.15.1,optimum_benchmark.backends.onnxruntime.ORTBackend,,,False,False,False,True,False,False,True,,CUDAExecutionProvider,1,True,False,False,1,True,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O2,True,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",,False,False,glue,300,sst2,train,True,optimum_benchmark.preprocessors.glue.GluePreprocessor,True,inference,optimum_benchmark.benchmarks.inference.InferenceBenchmark,42,False,10,10,64,16,1,64,64,3,3,2,80,3000,16000,100,openai/whisper-base,cuda:1,automatic-speech-recognition,main,,False,False,False,1.11.1.dev0,4.32.0.dev0,0.22.0.dev0,0.20.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,515637,0,0.172,372.0,0.622,10300.0,,,,,,,,,,,,,,,-47.08392603129445,55.35444947209653
whisper_auto_opt(None),onnxruntime,1.15.1,optimum_benchmark.backends.onnxruntime.ORTBackend,,,False,False,False,True,False,False,True,,CUDAExecutionProvider,1,True,False,False,1,True,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,,True,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",,False,False,glue,300,sst2,train,True,optimum_benchmark.preprocessors.glue.GluePreprocessor,True,inference,optimum_benchmark.benchmarks.inference.InferenceBenchmark,42,False,10,10,64,16,1,64,64,3,3,2,80,3000,16000,100,openai/whisper-base,cuda:1,automatic-speech-recognition,main,,False,False,False,1.11.1.dev0,4.32.0.dev0,0.22.0.dev0,0.20.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,515637,0,0.325,197.0,0.796,8040.0,,,,,,,,,,,,,,,-71.97724039829303,21.266968325791847
whisper_auto_opt(O1),onnxruntime,1.15.1,optimum_benchmark.backends.onnxruntime.ORTBackend,,,False,False,False,True,False,False,True,,CUDAExecutionProvider,1,True,False,False,1,True,False,True,False,False,False,False,True,False,False,False,False,True,False,False,False,False,True,True,O1,True,False,False,QOperator,IntegerOps,QUInt8,False,QInt8,True,False,False,"['MatMul', 'Add']",,False,False,glue,300,sst2,train,True,optimum_benchmark.preprocessors.glue.GluePreprocessor,True,inference,optimum_benchmark.benchmarks.inference.InferenceBenchmark,42,False,10,10,64,16,1,64,64,3,3,2,80,3000,16000,100,openai/whisper-base,cuda:1,automatic-speech-recognition,main,,False,False,False,1.11.1.dev0,4.32.0.dev0,0.22.0.dev0,0.20.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,515637,0,0.325,197.0,0.791,8090.0,,,,,,,,,,,,,,,-71.97724039829303,22.021116138763208
whisper_baseline,pytorch,2.0.1+cu117,optimum_benchmark.backends.pytorch.PyTorchBackend,,,False,False,False,,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,inference,optimum_benchmark.benchmarks.inference.InferenceBenchmark,42,False,10,10,64,16,1,64,64,3,3,2,80,3000,16000,100,openai/whisper-base,cuda:1,automatic-speech-recognition,main,,False,False,False,1.11.1.dev0,4.32.0.dev0,0.22.0.dev0,0.20.0.dev0,3.9.17,Linux, AMD EPYC 7742 64-Core Processor,128,515637,0,0.0911,703.0,0.966,6630.0,False,False,False,False,False,False,inductor,,,False,False,,True,True,0.0,0.0
