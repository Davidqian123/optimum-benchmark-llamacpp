_target_: src.backend.onnxruntime.ORTBackend

name: onnxruntime
version: ${onnxruntime_version:} # resolved by onnxruntime config dataclass

provider: ${infer_provider:${device}}
use_io_binding: ${is_gpu:${device}}

enable_profiling: ${benchmark.profiling}
inter_op_num_threads: null
intra_op_num_threads: null

enable_optimization: false
optimization:
  optimization_level: 1 # 0, 1, 2, 99
  optimize_for_gpu: ${is_gpu:${device}}
  fp16: false
  enable_transformers_specific_optimizations: true
  disable_gelu_fusion: false
  disable_layer_norm_fusion: false
  disable_attention_fusion: false
  disable_skip_layer_norm_fusion: true
  enable_gelu_approximation: false
  disable_bias_skip_layer_norm_fusion: false
  disable_bias_gelu_fusion: false
  use_mask_index: false
  no_attention_mask: false
  disable_embed_layer_norm_fusion: true
  disable_shape_inference: false
  use_multi_head_attention: false
  enable_gemm_fast_gelu_fusion: false
  use_raw_attention_mask: false
  disable_group_norm_fusion: true
  disable_packed_kv: true

enable_quantization: false
quantization:
  is_static: false
  format: QOperator # QOperator, QDQ
  mode: IntegerOps # QLinearOps, IntegerOps
  activations_dtype: QUInt8 # QInt8, QUInt8
  activations_symmetric: false
  weights_dtype: QInt8 # QInt8, QUInt8
  weights_symmetric: true
  per_channel: false
  reduce_range: false